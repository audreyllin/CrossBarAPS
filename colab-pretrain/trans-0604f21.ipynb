{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12062706,"sourceType":"datasetVersion","datasetId":7592589}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nnotebook_start = time.time()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T22:26:31.307435Z","iopub.execute_input":"2025-06-04T22:26:31.307855Z","iopub.status.idle":"2025-06-04T22:26:31.318730Z","shell.execute_reply.started":"2025-06-04T22:26:31.307816Z","shell.execute_reply":"2025-06-04T22:26:31.316977Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Cell 1: Environment Setup - FIXED\n# =================================\nimport os\nimport sys\nimport json\nimport shutil\nimport numpy as np\nimport torch\nimport transformers\nfrom datasets import Dataset, load_dataset, DatasetDict\nfrom peft import LoraConfig, get_peft_model\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForLanguageModeling\n)\n\n# Set environment variables\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"OMP_NUM_THREADS\"] = \"1\"\nos.environ[\"NO_TF\"] = \"1\"  # Prevent TensorFlow import issues\n\n# Install required packages\n!pip uninstall -y tensorflow  # Remove to prevent conflicts\n!pip install --upgrade pip setuptools wheel\n!pip install numpy==1.26.4 scipy==1.11.4\n!pip install torch==2.2.1+cpu torchvision==0.17.1+cpu torchaudio==2.2.1+cpu --index-url https://download.pytorch.org/whl/cpu\n!pip install transformers==4.41.2 peft==0.10.0 datasets==2.18.0 accelerate==0.29.1\n!pip install einops==0.7.0 tokenizers==0.19.1 sentencepiece==0.2.0\n!pip install scikit-learn==1.2.2 matplotlib==3.7.2\n!pip install langchain==0.1.16 faiss-cpu==1.7.4 tqdm==4.66.2 pandas==2.2.2\n\n# Verify installations\nprint(\"\\n=== Core Package Versions ===\")\nprint(f\"Python: {sys.version}\")\nprint(f\"NumPy: {np.__version__}\")\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"Transformers: {transformers.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T22:26:31.320711Z","iopub.execute_input":"2025-06-04T22:26:31.321036Z","iopub.status.idle":"2025-06-04T22:27:03.743717Z","shell.execute_reply.started":"2025-06-04T22:26:31.321011Z","shell.execute_reply":"2025-06-04T22:27:03.741799Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n","output_type":"stream"},{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (80.9.0)\nRequirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\nRequirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: scipy==1.11.4 in /usr/local/lib/python3.11/dist-packages (1.11.4)\nLooking in indexes: https://download.pytorch.org/whl/cpu\nRequirement already satisfied: torch==2.2.1+cpu in /usr/local/lib/python3.11/dist-packages (2.2.1+cpu)\nRequirement already satisfied: torchvision==0.17.1+cpu in /usr/local/lib/python3.11/dist-packages (0.17.1+cpu)\nRequirement already satisfied: torchaudio==2.2.1+cpu in /usr/local/lib/python3.11/dist-packages (2.2.1+cpu)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1+cpu) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1+cpu) (4.13.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1+cpu) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1+cpu) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1+cpu) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.1+cpu) (2023.10.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.1+cpu) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17.1+cpu) (11.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.1+cpu) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.1+cpu) (1.3.0)\nRequirement already satisfied: transformers==4.41.2 in /usr/local/lib/python3.11/dist-packages (4.41.2)\nRequirement already satisfied: peft==0.10.0 in /usr/local/lib/python3.11/dist-packages (0.10.0)\nRequirement already satisfied: datasets==2.18.0 in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: accelerate==0.29.1 in /usr/local/lib/python3.11/dist-packages (0.29.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (4.66.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (7.0.0)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (2.2.1+cpu)\nRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (19.0.1)\nRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (0.7)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (0.3.7)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (2.2.2)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (0.70.15)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0) (2023.10.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (1.1.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0) (1.20.0)\nRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==2.18.0) (3.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2025.4.26)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.13.0->peft==0.10.0) (1.3.0)\nRequirement already satisfied: einops==0.7.0 in /usr/local/lib/python3.11/dist-packages (0.7.0)\nRequirement already satisfied: tokenizers==0.19.1 in /usr/local/lib/python3.11/dist-packages (0.19.1)\nRequirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers==0.19.1) (0.31.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (2023.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (4.66.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (1.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1) (2025.4.26)\nRequirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: matplotlib==3.7.2 in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2) (23.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.7.2) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2) (1.17.0)\nRequirement already satisfied: langchain==0.1.16 in /usr/local/lib/python3.11/dist-packages (0.1.16)\nRequirement already satisfied: faiss-cpu==1.7.4 in /usr/local/lib/python3.11/dist-packages (1.7.4)\nRequirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.11/dist-packages (4.66.2)\nRequirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (2.2.2)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (2.0.40)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (3.11.18)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (0.6.7)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (1.33)\nRequirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (0.0.38)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (0.1.53)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (0.0.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (0.1.147)\nRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (2.11.4)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (2.32.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.1.16) (8.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.20.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.16) (3.0.0)\nRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain==0.1.16) (23.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.10.16)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.1.16) (2.4.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.16) (3.1.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16) (1.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.16) (1.3.1)\n\n=== Core Package Versions ===\nPython: 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\nNumPy: 1.26.4\nPyTorch: 2.2.1+cpu\nTransformers: 4.41.2\nCUDA available: False\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 2: Model Loading - FIXED\n# ============================\nMODEL_NAME = \"gpt2\"\n\ndef print_memory():\n    \"\"\"Memory usage diagnostics\"\"\"\n    import psutil\n    ram = psutil.virtual_memory()\n    print(f\"RAM: {ram.percent:.1f}% ({ram.used/1024**3:.1f}/{ram.total/1024**3:.1f}GB)\")\n\ndef load_model(model_name):\n    print(f\"\\n=== Loading Model: {model_name} ===\")\n    print_memory()\n    \n    device = \"cpu\"\n    torch_dtype = torch.float32\n    \n    try:\n        print(\"Attempting standard CPU load...\")\n        model = AutoModelForCausalLM.from_pretrained(\n            model_name,\n            device_map=None,\n            torch_dtype=torch_dtype\n        ).to(device)\n        print(\"\\n‚úÖ Model loaded successfully on CPU!\")\n        return model\n    except Exception as e:\n        print(f\"\\n‚ùå Standard load failed: {str(e)}\")\n        raise RuntimeError(\"Unable to load model on CPU\")\n\nmodel = load_model(MODEL_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T22:27:03.744928Z","iopub.execute_input":"2025-06-04T22:27:03.746045Z","iopub.status.idle":"2025-06-04T22:27:04.626338Z","shell.execute_reply.started":"2025-06-04T22:27:03.746008Z","shell.execute_reply":"2025-06-04T22:27:04.624282Z"}},"outputs":[{"name":"stdout","text":"\n=== Loading Model: gpt2 ===\nRAM: 4.5% (1.0/31.4GB)\nAttempting standard CPU load...\n\n‚úÖ Model loaded successfully on CPU!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 3: Tokenizer Setup - FIXED\n# ==============================\ndef load_tokenizer(model_name):\n    try:\n        tokenizer = AutoTokenizer.from_pretrained(\n            model_name,\n            padding_side=\"right\"\n        )\n        if tokenizer.pad_token is None:\n            tokenizer.pad_token = tokenizer.eos_token\n        print(\"Tokenizer loaded successfully\")\n        return tokenizer\n    except Exception as e:\n        print(f\"Tokenizer loading failed: {str(e)}\")\n        raise\n\ntokenizer = load_tokenizer(MODEL_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T22:27:04.628802Z","iopub.execute_input":"2025-06-04T22:27:04.629263Z","iopub.status.idle":"2025-06-04T22:27:05.013010Z","shell.execute_reply.started":"2025-06-04T22:27:04.629231Z","shell.execute_reply":"2025-06-04T22:27:05.011534Z"}},"outputs":[{"name":"stdout","text":"Tokenizer loaded successfully\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Cell 4: Dataset Preparation - FIXED\n# ==================================\ndef prepare_dataset(file_path=\"/kaggle/input/database4\", max_samples=1000):\n    try:\n        # Check if path exists\n        if not os.path.exists(file_path):\n            raise FileNotFoundError(f\"Dataset path not found: {file_path}\")\n        \n        print(f\"Loading dataset from: {file_path}\")\n        \n        # Check if it's a directory or file\n        if os.path.isdir(file_path):\n            # Load all JSON files in directory\n            json_files = [f for f in os.listdir(file_path) if f.endswith('.json')]\n            if not json_files:\n                raise ValueError(f\"No JSON files found in directory: {file_path}\")\n            \n            data_files = [os.path.join(file_path, f) for f in json_files]\n            print(f\"Found {len(json_files)} JSON files\")\n            dataset = load_dataset('json', data_files=data_files, split=f'train[:{max_samples}]')\n        else:\n            # Single file\n            dataset = load_dataset('json', data_files=file_path, split=f'train[:{max_samples}]')\n        \n        # Ensure text column exists\n        if 'text' not in dataset.column_names:\n            # Try to find a text-like column\n            text_candidates = [col for col in dataset.column_names \n                              if any(keyword in col.lower() for keyword in ['text', 'content', 'body', 'article'])]\n            \n            if text_candidates:\n                print(f\"Renaming column '{text_candidates[0]}' to 'text'\")\n                dataset = dataset.rename_column(text_candidates[0], 'text')\n            else:\n                # If no text-like column, concatenate all string columns\n                print(\"Concatenating all string columns to create 'text'\")\n                string_cols = [col for col in dataset.column_names if dataset.features[col].dtype == 'string']\n                \n                def combine_columns(examples):\n                    return {'text': ' '.join(str(examples[col]) for col in string_cols)}\n                \n                dataset = dataset.map(combine_columns, batched=True)\n        \n        print(f\"‚úÖ Loaded dataset with {len(dataset)} samples\")\n        return dataset\n    \n    except Exception as e:\n        print(f\"\\n‚ùå Dataset loading failed: {str(e)}\")\n        print(\"Creating fallback dataset...\")\n        return create_fallback_dataset()\n\ndef create_fallback_dataset():\n    \"\"\"Create cryptocurrency sample dataset\"\"\"\n    sample_texts = [\n        \"Cryptocurrency is a digital asset designed to work as a medium of exchange.\",\n        \"Blockchain technology enables secure peer-to-peer transactions.\",\n        \"Bitcoin was the first decentralized cryptocurrency created in 2009.\",\n        \"Ethereum introduced smart contracts to blockchain technology.\",\n        \"DeFi (Decentralized Finance) aims to recreate traditional financial systems without intermediaries.\",\n        \"NFTs (Non-Fungible Tokens) represent unique digital assets on the blockchain.\",\n        \"Cryptocurrency mining involves validating transactions and adding them to the blockchain.\",\n        \"Stablecoins are cryptocurrencies pegged to stable assets like the US dollar.\",\n        \"Cryptocurrency exchanges allow users to trade digital assets.\",\n        \"Wallet security is crucial for protecting cryptocurrency holdings.\"\n    ]\n    return Dataset.from_dict({\"text\": sample_texts})\n\ndef safe_tokenize(examples):\n    \"\"\"Tokenization with error handling\"\"\"\n    try:\n        tokenized = tokenizer(\n            examples[\"text\"],\n            truncation=True,\n            max_length=128,  # Reduced length for efficiency\n            padding=\"max_length\",\n            return_tensors=\"pt\"\n        )\n        return {\n            \"input_ids\": tokenized[\"input_ids\"].tolist(),\n            \"attention_mask\": tokenized[\"attention_mask\"].tolist(),\n            \"labels\": tokenized[\"input_ids\"].tolist()\n        }\n    except Exception:\n        return {\n            \"input_ids\": [[0]*128],\n            \"attention_mask\": [[1]*128],\n            \"labels\": [[0]*128]\n        }\n\nprint(\"\\n=== Starting Data Processing ===\")\ndataset = prepare_dataset(\"/kaggle/input/database4\")\n\n# Tokenize dataset\ntokenized_dataset = dataset.map(safe_tokenize, batched=True, batch_size=4)\ntokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n\n# Split dataset\nsplit_datasets = tokenized_dataset.train_test_split(test_size=0.2)\ntokenized_dataset = DatasetDict({\n    \"train\": split_datasets[\"train\"],\n    \"test\": split_datasets[\"test\"]\n})\nprint(f\"‚úÖ Dataset split: {len(tokenized_dataset['train'])} train, {len(tokenized_dataset['test'])} test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T22:27:05.014481Z","iopub.execute_input":"2025-06-04T22:27:05.014812Z","iopub.status.idle":"2025-06-04T22:27:05.192248Z","shell.execute_reply.started":"2025-06-04T22:27:05.014780Z","shell.execute_reply":"2025-06-04T22:27:05.190488Z"}},"outputs":[{"name":"stdout","text":"\n=== Starting Data Processing ===\nLoading dataset from: /kaggle/input/database4\n\n‚ùå Dataset loading failed: No JSON files found in directory: /kaggle/input/database4\nCreating fallback dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76db970d346b4cf7a728d1db43f5471c"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Dataset split: 8 train, 2 test\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Cell 5: Training Configuration - FIXED\n# =====================================\n# Enable gradient checkpointing\nmodel.gradient_checkpointing_enable()\n\n# LoRA configuration\npeft_config = LoraConfig(\n    r=8,  # Reduced from 16 for CPU efficiency\n    lora_alpha=16,\n    target_modules=[\"attn.c_attn\", \"attn.c_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\n# Training arguments optimized for CPU\ntraining_args = TrainingArguments(\n    output_dir=f\"./{MODEL_NAME}-crypto-expert\",\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=2,  # Reduced accumulation steps\n    num_train_epochs=1,\n    learning_rate=1e-4,  # Lower learning rate for CPU\n    optim=\"adamw_torch\",\n    logging_steps=5,\n    # FIXED: Match evaluation and save strategies\n    evaluation_strategy=\"epoch\",  # Changed to match save_strategy\n    save_strategy=\"epoch\",\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    warmup_ratio=0.1,\n    lr_scheduler_type=\"linear\",\n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    # FIXED: Use updated parameter name\n    use_cpu=True  # Instead of deprecated no_cuda=True\n)\n\n# Prepare model\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()\n\n# Data collator\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T22:27:05.194762Z","iopub.execute_input":"2025-06-04T22:27:05.195116Z","iopub.status.idle":"2025-06-04T22:27:05.277288Z","shell.execute_reply.started":"2025-06-04T22:27:05.195082Z","shell.execute_reply":"2025-06-04T22:27:05.273559Z"}},"outputs":[{"name":"stdout","text":"trainable params: 442,368 || all params: 124,882,176 || trainable%: 0.35422829275492446\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Cell 6: Training Execution - FIXED\n# =================================\ndef train_model(model, tokenized_dataset, training_args):\n    \"\"\"Execute the training process\"\"\"\n    model.config.use_cache = False  # Disable cache for gradient checkpointing\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_dataset[\"train\"],\n        eval_dataset=tokenized_dataset[\"test\"],\n        data_collator=data_collator\n    )\n    \n    print(\"\\n=== Starting Training ===\")\n    trainer.train()\n    \n    # Save model\n    output_dir = training_args.output_dir\n    model.save_pretrained(output_dir)\n    tokenizer.save_pretrained(output_dir)\n    print(f\"\\n‚úÖ Model saved to {output_dir}\")\n    return trainer\n\ntrainer = train_model(model, tokenized_dataset, training_args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T22:27:05.279438Z","iopub.execute_input":"2025-06-04T22:27:05.279952Z","iopub.status.idle":"2025-06-04T22:27:18.562398Z","shell.execute_reply.started":"2025-06-04T22:27:05.279904Z","shell.execute_reply":"2025-06-04T22:27:18.560828Z"}},"outputs":[{"name":"stdout","text":"\n=== Starting Training ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/2 00:06, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>3.624588</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Model saved to ./gpt2-crypto-expert\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Cell 7: Enhanced Model Saving with Shard Support\n# ===============================================\n\n# Add missing import\nfrom typing import Optional\n\ndef save_model_artifacts(\n    model, \n    tokenizer, \n    training_args: Optional[TrainingArguments] = None, \n    output_dir: str = \"/kaggle/working/gpt2-lora-trained\"\n) -> str:\n    \"\"\"\n    Save all model artifacts with comprehensive verification.\n    Handles both single-file and sharded model formats.\n    \"\"\"\n    # Create output directory\n    os.makedirs(output_dir, exist_ok=True)\n    print(f\"\\nüíæ Saving model artifacts to: {output_dir}\")\n    \n    # For LoRA models - DON'T merge adapters before saving\n    # We want to save the adapter separately\n    print(\"üíΩ Saving model and adapter...\")\n    \n    # Save the entire model (base model + adapter)\n    model.save_pretrained(\n        output_dir,\n        safe_serialization=True,\n        state_dict=model.state_dict()  # Save the complete state including LoRA\n    )\n    \n    # Save tokenizer\n    print(\"üî§ Saving tokenizer...\")\n    tokenizer.save_pretrained(output_dir)\n    \n    # Save training arguments if provided\n    if training_args is not None:\n        print(\"üìù Saving training arguments...\")\n        try:\n            args_path = os.path.join(output_dir, \"training_args.json\")\n            if hasattr(training_args, 'to_dict'):\n                with open(args_path, \"w\") as f:\n                    json.dump(training_args.to_dict(), f, indent=2)\n            elif hasattr(training_args, 'to_json_string'):\n                with open(args_path, \"w\") as f:\n                    f.write(training_args.to_json_string())\n            else:\n                print(\"‚ö†Ô∏è Warning: TrainingArguments has no serialization method\")\n        except Exception as e:\n            print(f\"‚ö†Ô∏è Warning: Failed to save training args - {str(e)}\")\n    \n    # Verify the adapter files were saved\n    required_files = ['adapter_config.json', 'adapter_model.safetensors']\n    missing_files = []\n    for file in required_files:\n        if not os.path.exists(os.path.join(output_dir, file)):\n            missing_files.append(file)\n    \n    if missing_files:\n        print(f\"\\n‚ö†Ô∏è Warning: Missing adapter files: {missing_files}\")\n        print(\"Trying alternative save method...\")\n        # Explicitly save the adapter\n        model.save_pretrained(\n            output_dir,\n            safe_serialization=True,\n            adapter_only=True  # This ensures adapter files are saved\n        )\n    \n    print(\"\\nüîç Verifying saved files:\")\n    for file in os.listdir(output_dir):\n        size = os.path.getsize(os.path.join(output_dir, file)) / 1024\n        print(f\"- {file} ({size:.2f} KB)\")\n    \n    return output_dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T22:29:15.933109Z","iopub.execute_input":"2025-06-04T22:29:15.933607Z","iopub.status.idle":"2025-06-04T22:29:15.946980Z","shell.execute_reply.started":"2025-06-04T22:29:15.933576Z","shell.execute_reply":"2025-06-04T22:29:15.945466Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Cell 8: Robust Model Loading and Testing with PEFT support\n# ========================================================\ndef load_and_test_model(\n    model_path: str = \"/kaggle/working/gpt2-lora-trained\", \n    max_length: int = 160,\n    test_prompts: Optional[list] = None,\n    is_peft_model: bool = True\n):\n    \"\"\"\n    Load and test a saved model with comprehensive error handling\n    \"\"\"\n    print(f\"\\nüîç Preparing to load model from: {model_path}\")\n    \n    # Verify model directory exists\n    if not os.path.exists(model_path):\n        raise ValueError(f\"Model directory {model_path} does not exist\")\n    \n    # Show directory contents for debugging\n    print(\"\\nüìÇ Model directory contents:\")\n    for f in sorted(os.listdir(model_path)):\n        size = os.path.getsize(os.path.join(model_path, f)) / 1024\n        print(f\"- {f} ({size:.2f} KB)\")\n    \n    try:\n        print(\"\\nüîÑ Loading tokenizer...\")\n\n        tokenizer = AutoTokenizer.from_pretrained(\n            model_path,\n            local_files_only=True\n        )\n        \n        print(\"\\nüîÑ Loading model...\")\n        if is_peft_model:\n            # First check if we have adapter files\n            adapter_files = [\n                f for f in os.listdir(model_path) \n                if f.startswith('adapter_') or f == 'adapter_config.json'\n            ]\n            \n            if not adapter_files:\n                print(\"‚ö†Ô∏è No adapter files found. Loading as regular model.\")\n                model = AutoModelForCausalLM.from_pretrained(\n                    model_path,\n                    device_map=\"auto\",\n                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n                    local_files_only=True\n                )\n            else:\n                print(f\"Found adapter files: {adapter_files}\")\n                # Load base model first\n                base_model = AutoModelForCausalLM.from_pretrained(\n                    model_path,\n                    device_map=\"auto\",\n                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n                    local_files_only=True\n                )\n                \n                # Then load the PEFT adapter\n                model = PeftModel.from_pretrained(\n                    base_model,\n                    model_path,\n                    local_files_only=True\n                )\n                \n                # Merge and unload for inference\n                model = model.merge_and_unload()\n        else:\n            # For regular models\n            model = AutoModelForCausalLM.from_pretrained(\n                model_path,\n                device_map=\"auto\",\n                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n                local_files_only=True\n            )\n            \n        print(\"\\nüéâ Model loaded successfully!\")\n        \n        # Default test prompts if none provided\n        if test_prompts is None:\n            test_prompts = [\n                \"What is hardware wallet?? \",\n                \"What is Proof of Work (PoW)?? \",\n                \"What is cryptography?? \",\n                \"What is Peer-to-Peer (P2P)?? \",\n                \"What is block chain?? \",\n                \"What is private key?? \"\n            ]\n        \n        # Create pipeline - REMOVED device parameter since we're using device_map=\"auto\"\n        print(\"\\nüöÄ Creating text generation pipeline...\")\n        pipe = pipeline(\n            \"text-generation\",\n            model=model,\n            tokenizer=tokenizer,\n            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n        )\n        \n        # Run tests\n        print(\"\\nüß™ Running generation tests...\")\n        for i, prompt in enumerate(test_prompts, 1):\n            print(f\"\\nüîπ Test {i}: {prompt}\")\n            output = pipe(\n                prompt,\n                max_length=max_length,\n                do_sample=True,\n                temperature=0.7,\n                top_p=0.9,\n                num_return_sequences=1,\n                repetition_penalty=1.2\n            )\n            print(\"üí¨ Response:\", output[0]['generated_text'])\n            \n        return model, tokenizer\n        \n    except Exception as e:\n        print(f\"\\n‚ùå Critical error loading model: {str(e)}\")\n        print(\"\\nüõ†Ô∏è Debugging info:\")\n        print(f\"- Path: {os.path.abspath(model_path)}\")\n        print(f\"- Directory exists: {os.path.exists(model_path)}\")\n        if os.path.exists(model_path):\n            print(\"- Contents:\", os.listdir(model_path))\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T22:29:15.948522Z","iopub.execute_input":"2025-06-04T22:29:15.948834Z","iopub.status.idle":"2025-06-04T22:29:15.985628Z","shell.execute_reply.started":"2025-06-04T22:29:15.948812Z","shell.execute_reply":"2025-06-04T22:29:15.983818Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Main execution\nif __name__ == \"__main__\":\n    model_path = \"/kaggle/working/gpt2-lora-trained\"\n    \n    # Save model artifacts\n    save_model_artifacts(model, tokenizer, training_args)\n    \n    # Load with explicit path and PEFT flag\n    load_and_test_model(model_path, is_peft_model=True)\n    \n    # Test with custom prompts\n    custom_prompts = [\n        \"What is software wallet, and what's the difference between hardware and software wallet? \",\n        \"What is PoW? \",\n        \"Explain PoW in 1 sentence. \",\n        \"Describe the key features of PoW using 3 words. \",\n        \"What is PoM? Is it something related to cryptography? \",\n        \"What is a cryptographic product? \",\n        \"What is P2P? \",\n        \"What is block chain? \",\n        \"What is public key, and what's the difference between private and public key? \"\n    ]\n    load_and_test_model(model_path, test_prompts=custom_prompts, is_peft_model=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T22:29:15.986759Z","iopub.execute_input":"2025-06-04T22:29:15.987094Z","iopub.status.idle":"2025-06-04T22:29:16.907904Z","shell.execute_reply.started":"2025-06-04T22:29:15.987071Z","shell.execute_reply":"2025-06-04T22:29:16.905400Z"}},"outputs":[{"name":"stdout","text":"\nüíæ Saving model artifacts to: /kaggle/working/gpt2-lora-trained\nüíΩ Saving model and adapter...\nüî§ Saving tokenizer...\nüìù Saving training arguments...\n\nüîç Verifying saved files:\n- merges.txt (445.62 KB)\n- adapter_model.safetensors (1733.91 KB)\n- README.md (4.96 KB)\n- tokenizer_config.json (0.49 KB)\n- training_args.json (3.82 KB)\n- adapter_config.json (0.62 KB)\n- vocab.json (779.45 KB)\n- special_tokens_map.json (0.13 KB)\n- tokenizer.json (2058.55 KB)\n\nüîç Preparing to load model from: /kaggle/working/gpt2-lora-trained\n\nüìÇ Model directory contents:\n- README.md (4.96 KB)\n- adapter_config.json (0.62 KB)\n- adapter_model.safetensors (1733.91 KB)\n- merges.txt (445.62 KB)\n- special_tokens_map.json (0.13 KB)\n- tokenizer.json (2058.55 KB)\n- tokenizer_config.json (0.49 KB)\n- training_args.json (3.82 KB)\n- vocab.json (779.45 KB)\n\nüîÑ Loading tokenizer...\n\nüîÑ Loading model...\nFound adapter files: ['adapter_model.safetensors', 'adapter_config.json']\n\n‚ùå Critical error loading model: name 'PeftModel' is not defined\n\nüõ†Ô∏è Debugging info:\n- Path: /kaggle/working/gpt2-lora-trained\n- Directory exists: True\n- Contents: ['merges.txt', 'adapter_model.safetensors', 'README.md', 'tokenizer_config.json', 'training_args.json', 'adapter_config.json', 'vocab.json', 'special_tokens_map.json', 'tokenizer.json']\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_543/81389042.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Load with explicit path and PEFT flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mload_and_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Test with custom prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_543/3882793668.py\u001b[0m in \u001b[0;36mload_and_test_model\u001b[0;34m(model_path, max_length, test_prompts, is_peft_model)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;31m# Then load the PEFT adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 model = PeftModel.from_pretrained(\n\u001b[0m\u001b[1;32m     60\u001b[0m                     \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'PeftModel' is not defined"],"ename":"NameError","evalue":"name 'PeftModel' is not defined","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"\nnotebook_end = time.time()\nprint(f\"Total notebook execution time: {notebook_end - notebook_start:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T22:29:16.908667Z","iopub.status.idle":"2025-06-04T22:29:16.908988Z","shell.execute_reply.started":"2025-06-04T22:29:16.908835Z","shell.execute_reply":"2025-06-04T22:29:16.908847Z"}},"outputs":[],"execution_count":null}]}