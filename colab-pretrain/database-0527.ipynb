{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy==1.24.0 scipy==1.10.0 spacy==3.7.4 scikit-learn==1.2.2 pandas==1.5.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T18:34:13.827843Z","iopub.execute_input":"2025-05-27T18:34:13.828146Z","iopub.status.idle":"2025-05-27T18:34:25.867866Z","shell.execute_reply.started":"2025-05-27T18:34:13.828123Z","shell.execute_reply":"2025-05-27T18:34:25.866410Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy==1.24.0 in /usr/local/lib/python3.11/dist-packages (1.24.0)\nRequirement already satisfied: scipy==1.10.0 in /usr/local/lib/python3.11/dist-packages (1.10.0)\nRequirement already satisfied: spacy==3.7.4 in /usr/local/lib/python3.11/dist-packages (3.7.4)\nRequirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.11/dist-packages (1.2.2)\nCollecting pandas==1.5.3\n  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (0.9.4)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (2.11.4)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (75.2.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (25.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (3.5.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2025.2)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.7.4) (1.3.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (0.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.4) (2025.4.26)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy==3.7.4) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy==3.7.4) (0.1.5)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy==3.7.4) (8.1.8)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.4.0,>=0.1.0->spacy==3.7.4) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy==3.7.4) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.7.4) (1.2.1)\nDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pandas\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.3\n    Uninstalling pandas-2.2.3:\n      Successfully uninstalled pandas-2.2.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\ncudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.0 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.24.0 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.24.0 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nvisions 0.8.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\npyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.24.0 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nseaborn 0.12.2 requires numpy!=1.24.0,>=1.17, but you have numpy 1.24.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.24.0 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\nmizani 0.13.2 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\npymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.0 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nplotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\nxarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pandas-1.5.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# English model\n!python -m spacy download en_core_web_sm-3.7.0 --direct\n\n# Chinese model (old version)\n!pip install https://github.com/explosion/spacy-models/releases/download/zh_core_web_sm-3.7.0/zh_core_web_sm-3.7.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T18:34:25.869695Z","iopub.execute_input":"2025-05-27T18:34:25.870070Z","iopub.status.idle":"2025-05-27T18:34:41.736029Z","shell.execute_reply.started":"2025-05-27T18:34:25.870036Z","shell.execute_reply":"2025-05-27T18:34:41.735021Z"}},"outputs":[{"name":"stdout","text":"Collecting en-core-web-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.0) (3.7.4)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.9.4)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.11.4)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (75.2.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (25.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.24.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.3.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2025.4.26)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.1.5)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.1.8)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.2.1)\nInstalling collected packages: en-core-web-sm\n  Attempting uninstall: en-core-web-sm\n    Found existing installation: en_core_web_sm 3.8.0\n    Uninstalling en_core_web_sm-3.8.0:\n      Successfully uninstalled en_core_web_sm-3.8.0\nSuccessfully installed en-core-web-sm-3.7.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nCollecting zh-core-web-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/zh_core_web_sm-3.7.0/zh_core_web_sm-3.7.0-py3-none-any.whl (48.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from zh-core-web-sm==3.7.0) (3.7.4)\nRequirement already satisfied: spacy-pkuseg<0.1.0,>=0.0.27 in /usr/local/lib/python3.11/dist-packages (from zh-core-web-sm==3.7.0) (0.0.33)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.9.4)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.11.4)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (75.2.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (25.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.24.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.3.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (2025.4.26)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.1.5)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (8.1.8)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->zh-core-web-sm==3.7.0) (1.2.1)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# --- Imports ---\nimport spacy\nfrom spacy.matcher import Matcher\nimport numpy as np\nimport os\nimport re\nimport joblib\nfrom collections import OrderedDict\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom spacy.lang.en import English\nfrom spacy.lang.zh import Chinese","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T18:34:41.737327Z","iopub.execute_input":"2025-05-27T18:34:41.737613Z","iopub.status.idle":"2025-05-27T18:34:46.235159Z","shell.execute_reply.started":"2025-05-27T18:34:41.737562Z","shell.execute_reply":"2025-05-27T18:34:46.233984Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"nlp_en = spacy.load(\"en_core_web_sm\")\nnlp_zh = spacy.load(\"zh_core_web_sm\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T18:34:46.237250Z","iopub.execute_input":"2025-05-27T18:34:46.237746Z","iopub.status.idle":"2025-05-27T18:34:49.226380Z","shell.execute_reply.started":"2025-05-27T18:34:46.237718Z","shell.execute_reply":"2025-05-27T18:34:49.225331Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# --- Enhanced SectionDetector Class ---\nclass SectionDetector:\n    def __init__(self, nlp=None, model_path=None):\n        \"\"\"Initialize with optional pre-trained model\"\"\"\n        self.nlp = nlp or spacy.load(\"en_core_web_sm\")\n        self.section_classifier = None\n        self.section_hierarchy = {}\n        self.matcher = None\n        self._initialize_section_patterns()\n        \n        if model_path:\n            self.load_model(model_path)\n\n    def _initialize_section_patterns(self):\n        \"\"\"Initialize multilingual section patterns and matcher\"\"\"\n        # Base patterns for English\n        self.section_hierarchy = {\n            'abstract': {'level': 1, 'patterns': [\n                [{\"LOWER\": \"abstract\"}],\n                [{\"IS_DIGIT\": True}, {\"LOWER\": \"abstract\"}]\n            ]},\n            'introduction': {'level': 1, 'patterns': [\n                [{\"LOWER\": \"introduction\"}],\n                [{\"IS_DIGIT\": True}, {\"LOWER\": \"introduction\"}]\n            ]},\n            'methods': {'level': 1, 'patterns': [\n                [{\"LOWER\": \"methods\"}],\n                [{\"LOWER\": \"materials\"}, {\"LOWER\": \"and\"}, {\"LOWER\": \"methods\"}],\n                [{\"IS_DIGIT\": True}, {\"LOWER\": \"methods\"}]\n            ]},\n            'results': {'level': 1, 'patterns': [\n                [{\"LOWER\": \"results\"}],\n                [{\"IS_DIGIT\": True}, {\"LOWER\": \"results\"}]\n            ]},\n            'discussion': {'level': 1, 'patterns': [\n                [{\"LOWER\": \"discussion\"}],\n                [{\"IS_DIGIT\": True}, {\"LOWER\": \"discussion\"}]\n            ]},\n            'conclusion': {'level': 1, 'patterns': [\n                [{\"LOWER\": \"conclusion\"}],\n                [{\"IS_DIGIT\": True}, {\"LOWER\": \"conclusion\"}]\n            ]},\n            'references': {'level': 1, 'patterns': [\n                [{\"LOWER\": \"references\"}],\n                [{\"LOWER\": \"bibliography\"}],\n                [{\"IS_DIGIT\": True}, {\"LOWER\": \"references\"}]\n            ]}\n        }\n\n        # Initialize matcher\n        self.matcher = Matcher(self.nlp.vocab)\n        self._refresh_matcher()\n\n    def _refresh_matcher(self):\n        \"\"\"Update matcher with current section patterns\"\"\"\n        self.matcher = Matcher(self.nlp.vocab)\n        for section, info in self.section_hierarchy.items():\n            for pattern in info['patterns']:\n                self.matcher.add(section.upper(), [pattern])\n\n    def add_custom_section(self, name, level, patterns):\n        \"\"\"Add domain-specific section patterns\"\"\"\n        self.section_hierarchy[name] = {\n            'level': level,\n            'patterns': patterns\n        }\n        self._refresh_matcher()\n\n    def _extract_raw_sections(self, text, use_ml):\n        \"\"\"Multilingual text segmentation with context-aware processing\"\"\"\n        doc = self.nlp(text)\n        matches = self.matcher(doc)\n        sections = OrderedDict()\n        current_section = \"header\"\n        last_end = 0\n\n        # Sort matches by start position\n        matches = sorted(matches, key=lambda x: x[1])\n\n        for match_id, start, end in matches:\n            section_name = self.nlp.vocab.strings[match_id].lower()\n            content = doc[last_end:start].text.strip()\n            \n            if content:\n                sections[current_section] = sections.get(current_section, []) + [content]\n            \n            current_section = self._classify_section(\n                doc[start:end].text, \n                section_name, \n                use_ml\n            )\n            \n            last_end = end\n\n        # Add remaining content\n        if last_end < len(doc):\n            sections[current_section] = sections.get(current_section, []) + [doc[last_end:].text.strip()]\n\n        return {k: \"\\n\".join(v) for k, v in sections.items()}\n\n    def _classify_section(self, header_text, rule_based_name, use_ml):\n        \"\"\"Hybrid classification decision\"\"\"\n        if use_ml and self.section_classifier:\n            try:\n                return self.section_classifier.predict([header_text])[0]\n            except Exception as e:\n                print(f\"ML classification failed: {e}, using rule-based\")\n        return rule_based_name\n\n    def _postprocess_sections(self, sections):\n        \"\"\"Multilingual hierarchy reconstruction\"\"\"\n        hierarchy_stack = []\n        final_sections = OrderedDict()\n        \n        for section_name, content in sections.items():\n            level = self._get_section_level(section_name)\n            \n            while hierarchy_stack and hierarchy_stack[-1]['level'] >= level:\n                hierarchy_stack.pop()\n            \n            hierarchy_stack.append({\n                'name': section_name,\n                'level': level\n            })\n            \n            hier_key = \"::\".join([n['name'] for n in hierarchy_stack])\n            final_sections[hier_key] = content\n\n        return final_sections\n\n    def _get_section_level(self, section_name):\n        \"\"\"Multilingual level detection with fuzzy matching\"\"\"\n        clean_name = section_name.lower().strip()\n        \n        for section, info in self.section_hierarchy.items():\n            if section in clean_name:\n                return info['level']\n        \n        similarity_threshold = 0.8\n        for section, info in self.section_hierarchy.items():\n            if self.nlp(section).similarity(self.nlp(clean_name)) > similarity_threshold:\n                return info['level']\n        \n        return 0  # Default level\n\n    def save_model(self, path):\n        \"\"\"Save complete detector state\"\"\"\n        state = {\n            'classifier': self.section_classifier,\n            'hierarchy': self.section_hierarchy,\n            'nlp_config': self.nlp.config\n        }\n        joblib.dump(state, path)\n        print(f\"Full detector state saved to {path}\")\n\n    def load_model(self, path):\n        \"\"\"Load complete detector state\"\"\"\n        state = joblib.load(path)\n        self.section_classifier = state['classifier']\n        self.section_hierarchy = state['hierarchy']\n        self.nlp = spacy.load(state['nlp_config']['lang'])\n        self._refresh_matcher()\n        print(f\"Full detector state loaded from {path}\")\n\n    class SpacyTransformer(BaseEstimator, TransformerMixin):\n        def __init__(self, nlp):\n            self.nlp = nlp\n            self.tokenizer = nlp.tokenizer\n            \n        def transform(self, X):\n            processed = []\n            for text in X:\n                doc = self.nlp(text)\n                features = [\n                    len(doc), \n                    len(list(doc.sents)),\n                    sum(1 for token in doc if token.is_title),\n                    sum(1 for token in doc if token.pos_ == \"NOUN\")\n                ]\n                processed.append(features)\n            return np.array(processed)\n            \n        def fit(self, X, y=None):\n            return self\n\n    def train_classifier(self, X_train, y_train):\n        self.section_classifier = Pipeline([\n            ('features', FeatureUnion([\n                ('tfidf', TfidfVectorizer(\n                    tokenizer=self._spacy_tokenizer,\n                    ngram_range=(1, 2),\n                    max_features=3000\n                )),\n                ('spacy', self.SpacyTransformer(self.nlp))\n            ])),\n            ('clf', LogisticRegression(\n                class_weight='balanced',\n                max_iter=1000,\n                C=0.1\n            ))\n        ])\n        self.section_classifier.fit(X_train, y_train)\n\n    def _spacy_tokenizer(self, text):\n        \"\"\"Language-aware tokenization\"\"\"\n        doc = self.nlp(text)\n        return [\n            token.lemma_.lower() \n            if not token.is_oov else token.text.lower()\n            for token in doc\n            if not token.is_stop \n            and not token.is_punct\n            and not token.is_space\n        ]\n\n    def calculate_accuracy(self, true_labels, predicted_labels):\n        return {\n            'precision': precision_score(true_labels, predicted_labels, average='weighted'),\n            'recall': recall_score(true_labels, predicted_labels, average='weighted'),\n            'f1': f1_score(true_labels, predicted_labels, average='weighted')\n        }\n\n    # --- Enhanced Multilingual Processing Pipeline ---\n    def process_papers_with_sections(paper_urls, model_path=None, output_dir=\"/kaggle/working/papers\", lang='en'):\n        \"\"\"Enhanced pipeline with multilingual support\"\"\"\n        # [Keep full function implementation as provided]\n        # ... (Full function code from original implementation)\n    \n    # --- Enhanced Evaluation Metrics ---\n    def calculate_extended_metrics(y_true, y_pred):\n        \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n        # [Keep full function implementation as provided]\n        # ... (Full function code from original implementation)\n    \n    # --- Updated Training Data Loading ---\n    def load_training_data():\n        \"\"\"Sample training data - replace with actual dataset\"\"\"\n        training_examples = [\n            (\"Abstract\", \"abstract\"),\n            (\"1. Introduction\", \"introduction\"),\n            (\"Methods and Materials\", \"methods\"),\n            (\"Experimental Results\", \"results\"),\n            (\"Discussion\", \"discussion\"),\n            (\"Conclusion\", \"conclusion\"),\n            (\"References\", \"references\"),\n            (\"摘要\", \"abstract\"),  # Chinese examples\n            (\"1. 引言\", \"introduction\"),\n            (\"方法\", \"methods\")\n        ]\n        \n        X_train = [text for text, label in training_examples]\n        y_train = [label for text, label in training_examples]\n        return X_train, y_train\n    \n    # --- Mock PDF Text Extraction Function ---\n    def get_paper_text(url):\n        \"\"\"Mock PDF text extraction - implement actual PDF processing\"\"\"\n        # In real implementation, use PyPDF2, pdfplumber, or similar\n        return f\"Sample text from {url}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T18:34:49.227330Z","iopub.execute_input":"2025-05-27T18:34:49.227815Z","iopub.status.idle":"2025-05-27T18:34:49.254444Z","shell.execute_reply.started":"2025-05-27T18:34:49.227787Z","shell.execute_reply":"2025-05-27T18:34:49.253382Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# --- Enhanced Multilingual Processing Pipeline ---\ndef process_papers_with_sections(paper_urls, model_path=None, output_dir=\"/kaggle/working/papers\", lang='en'):\n    \"\"\"Enhanced pipeline with multilingual support\"\"\"\n    # Initialize appropriate NLP pipeline\n    if lang == 'zh':\n        nlp = Chinese()\n        nlp.add_pipe(\"sentencizer\")\n    else:\n        nlp = English()\n        nlp.add_pipe(\"sentencizer\")\n    \n    # Initialize detector with language-specific settings\n    detector = SectionDetector(nlp=nlp)\n    \n    # Add Chinese section patterns\n    if lang == 'zh':\n        chinese_sections = {\n            '摘要': {'level': 1, 'patterns': [[{\"ORTH\": \"摘要\"}]]},\n            '引言': {'level': 1, 'patterns': [[{\"ORTH\": \"引言\"}]]},\n            '方法': {'level': 1, 'patterns': [[{\"ORTH\": \"方法\"}]]},\n            '结果': {'level': 1, 'patterns': [[{\"ORTH\": \"结果\"}]]},\n            '讨论': {'level': 1, 'patterns': [[{\"ORTH\": \"讨论\"}]]},\n            '结论': {'level': 1, 'patterns': [[{\"ORTH\": \"结论\"}]]},\n            '参考文献': {'level': 1, 'patterns': [[{\"ORTH\": \"参考文献\"}]]}\n        }\n        for name, config in chinese_sections.items():\n            detector.add_custom_section(name, config['level'], config['patterns'])\n    \n    if model_path and os.path.exists(model_path):\n        detector.load_model(model_path)\n        use_ml = True\n    else:\n        use_ml = False\n    \n    processed_papers = []\n    for url in paper_urls:\n        try:\n            # Assuming get_paper_text is implemented elsewhere\n            text = get_paper_text(url)\n            sections = detector.extract_sections(text, use_ml=use_ml)\n            processed_papers.append({\n                'url': url,\n                'sections': sections,\n                'language': lang\n            })\n        except Exception as e:\n            print(f\"Error processing {url}: {e}\")\n    \n    # Save results\n    if output_dir:\n        os.makedirs(output_dir, exist_ok=True)\n        for paper in processed_papers:\n            filename = os.path.join(output_dir, f\"{paper['url'].split('/')[-1]}.json\")\n            joblib.dump(paper, filename)\n    \n    return processed_papers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T18:34:49.255573Z","iopub.execute_input":"2025-05-27T18:34:49.255893Z","iopub.status.idle":"2025-05-27T18:34:49.284400Z","shell.execute_reply.started":"2025-05-27T18:34:49.255868Z","shell.execute_reply":"2025-05-27T18:34:49.283460Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# --- Enhanced Evaluation Metrics ---\ndef calculate_extended_metrics(y_true, y_pred):\n    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n    return {\n        'precision_macro': precision_score(y_true, y_pred, average='macro'),\n        'recall_macro': recall_score(y_true, y_pred, average='macro'),\n        'f1_macro': f1_score(y_true, y_pred, average='macro'),\n        'precision_weighted': precision_score(y_true, y_pred, average='weighted'),\n        'recall_weighted': recall_score(y_true, y_pred, average='weighted'),\n        'f1_weighted': f1_score(y_true, y_pred, average='weighted'),\n        'class_distribution': {\n            cls: {'true': y_true.count(cls), 'predicted': list(y_pred).count(cls)}\n            for cls in set(y_true + y_pred)\n        }\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T18:34:49.285377Z","iopub.execute_input":"2025-05-27T18:34:49.285699Z","iopub.status.idle":"2025-05-27T18:34:49.310619Z","shell.execute_reply.started":"2025-05-27T18:34:49.285677Z","shell.execute_reply":"2025-05-27T18:34:49.309639Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Load and verify training data\n    X_train, y_train = load_training_data()\n    \n    if not X_train or not y_train:\n        raise ValueError(\"Training data loading failed - check data sources\")\n    \n    if len(X_train) != len(y_train):\n        raise ValueError(\"Mismatched training data features/labels\")\n\n    # Initialize and train detector\n    detector = SectionDetector()\n    detector.train_classifier(X_train, y_train)\n    \n    # Save model\n    detector.save_model(\"/kaggle/working/section_classifier.joblib\")\n    \n    # Verify model saving\n    if not os.path.exists(\"/kaggle/working/section_classifier.joblib\"):\n        raise RuntimeError(\"Model saving failed\")\n\n    # Process papers\n    papers = process_papers_with_sections(\n        paper_urls = [\n            \"https://arxiv.org/pdf/2307.12874\",\n            \"https://arxiv.org/pdf/2303.12940\",\n            \"https://arxiv.org/pdf/1802.04351\",\n            \"https://arxiv.org/pdf/2306.08168\",\n            \"https://arxiv.org/pdf/2503.15964\",\n            \"https://www.jetir.org/papers/JETIR2405D82.pdf\",\n            \"https://www.cs.ucf.edu/~czou/research/subWallet-Blockchain-2019.pdf\",\n            \"https://www.cs.ucf.edu/~czou/research/Hossein-TrustCom-2020.pdf\",\n            \"https://www.cs.ucf.edu/~czou/research/HosseinDissertation-2020.pdf\",\n            \"https://dl.gi.de/server/api/core/bitstreams/aaa640a1-f8dd-4514-ad72-b809932072cc/content\",\n            \"https://eprint.iacr.org/2023/062.pdf\",\n            \"https://eprint.iacr.org/2022/075.pdf\",    \n            \"https://eprint.iacr.org/2023/1234.pdf\",\n            \"https://eprint.iacr.org/2020/300.pdf\",\n            \"https://eprint.iacr.org/2023/312.pdf\",\n            \"https://policyreview.info/pdf/policyreview-2016-3-427.pdf\",\n            \"https://eprint.iacr.org/2016/013.pdf\",\n            \"https://arxiv.org/pdf/1906.00245\",\n            \"https://escholarship.org/content/qt7fh678d6/qt7fh678d6.pdf?t=pn651y\",\n            \"https://re.public.polimi.it/bitstream/11311/1056221/6/11311-1056221%20Giudici.pdf\",\n            \"https://research-api.cbs.dk/ws/files/44436178/ole_bjerg_how_is_bitcoin_money_postprint.pdf\",\n            \"https://www.bis.org/fsi/publ/insights49.pdf\",\n            \"https://www.scirp.org/pdf/ojbm_1534496.pdf\",\n            \"https://www.bis.org/publ/work1066.pdf\",\n            \"http://khcnbinhduong.gov.vn/ImageUpload/file/TTTK%20KCN/2019/Nguon%20tin%20KHCN/Blockchain_A3.pdf\",\n            \"https://e-space.mmu.ac.uk/627269/1/Manuscript_Final%20JCLP.pdf\",\n            \"https://pdfs.semanticscholar.org/9900/c9c91f9f78fa0adb6915855084396654363c.pdf?_gl=1*7q1z9h*_gcl_au*MTkxMDg1NzA4NC4xNzQ4MDIxMDA4*_ga*Mjc1MDg5MDkuMTc0ODAyMTAwOA..*_ga_H7P4ZT52H5*czE3NDgwMjEwMDckbzEkZzEkdDE3NDgwMjExNzkkajE1JGwwJGgwJGR1YWNJOGg3VW43bWFscGZjZ056LU5TM0lXc0Jtc0drMW93\",\n            \"https://www.newyorkfed.org/medialibrary/media/research/epr/2024/EPR_2024_digital-assets_azar.pdf\",\n            \"https://journals.law.harvard.edu/hblr/wp-content/uploads/sites/87/2025/03/04_HLB_15_1_Noked171-216.pdf\",\n            \"https://www.stern.nyu.edu/sites/default/files/2024-07/Glucksman_Sak_2024.pdf\",\n            \"https://www.tigta.gov/sites/default/files/reports/2024-07/2024300030fr_0.pdf\",\n            \"https://www.fsb.org/uploads/Crypto-Council-for-Innovation.pdf\",\n            \"https://www.cs.ucf.edu/~czou/research/HosseinDissertation-2020.pdf\",\n            \"https://ndbf.nebraska.gov/sites/default/files/industries/Digital%20Asset%20Depository%20Nebraska%20Custody%20and%20Fiduciary%20Services%20Examination%20Manual.pdf\",\n            \"https://www.swlegal.com/media/filer_public/2d/f7/2df70b84-cb3c-4578-9943-8b3ea024abf9/sw_nl_january_2024_english.pdf\",\n            \"https://www.willkie.com/-/media/files/publications/2024/12/law360---sec-custody-rule-creates-crypto-compliance-conundrum.pdf\",\n            \"https://www.henrystewartpublications.com/sites/default/files/Opportunities%20in%20digital%20assets%20and%20digital%20custody-Tracking%20the%20modernisation%20of%20standard%20custody%20offering%20-%20Ignatowicz%20%26%20Taudes%20JSOC%2015-3.pdf\",\n            \"https://www.gdf.io/wp-content/uploads/2019/02/GDF-Crypto-Asset-Safekeeping_20-April-2019-2-cust-providers-additions-1-2.pdf\",\n            \"https://www.occ.gov/topics/charters-and-licensing/interpretations-and-actions/2020/int1170.pdf\",\n            \"https://www.gemini.com/static/documents/guide-to-crypto-custody.pdf\",\n            \"https://orbilu.uni.lu/bitstream/10993/62083/1/ZetzscheSinnigNikolakopoulou_Crypto%20custody_CMLJ%202024.pdf\",\n            \"https://www.esrb.europa.eu/pub/pdf/reports/esrb.cryptoassetsanddecentralisedfinance202305~9792140acd.en.pdf\",\n            \"https://repository.uel.ac.uk/download/df676586f4e9f8a89df529a36841d83d4750539805189a8951032ee4c2f0c16c/99798/challenges-and-approaches-to-regulating-decentralized-finance.pdf\",\n            \"https://repository.uel.ac.uk/download/ca8bad2f5fab17596c44927643b4da1473ef7ef79862fe3ca05ea9251bd4db8b/1599957/Financial%20Crime%20update%20%282020%29.pdf\",\n            \"https://www.iacpcybercenter.org/wp-content/uploads/2018/03/Bitcoin.pdf\",\n            \"https://www.ussc.gov/sites/default/files/pdf/training/Podcasts/SPT_Emerging-Tech-Terms.pdf\",\n            \"https://www.ussc.gov/sites/default/files/pdf/training/annual-national-training-seminar/2018-materials/emerging-tech_glossary-crypto.pdf\",\n            \"https://www.ussc.gov/sites/default/files/pdf/training/annual-national-training-seminar/2018-materials/emerging-tech_glossary-phishing.pdf\",\n            \"https://www.ussc.gov/sites/default/files/pdf/training/annual-national-training-seminar/2018/Emerging_Tech_Bitcoin_Crypto.pdf\",\n            \"https://www.ussc.gov/sites/default/files/pdf/training/annual-national-training-seminar/2019/emerging-tech_white-paper.pdf\",\n            \"https://openaccess.uoc.edu/bitstream/10609/151551/1/Rahmanikivi_cbt22_empirical.pdf\",\n            \"https://ics.uci.edu/~dabrowsa/dabrowski-defi21-hwwallet.pdf\",\n            \"https://fc19.ifca.ai/preproceedings/93-preproceedings.pdf\",\n            \"https://www.jkroll.com/papers/bitcoin_threshold_signatures.pdf\",\n            \"https://corporates.db.com/files/documents/publications/db-polygo-digital-id-wp-42pp-web-secured.pdf\",\n            \"https://www.napier.ac.uk/-/media/worktribe/output-2839021/smart-contract-attacks-and-protections.ashx\",\n            \"https://www.cyprusbarassociation.org/images/6._Crypto_Wallets.pdf\",\n            \"https://computerscience.unicam.it/marcantoni/tesi/Ethereum%20Smart%20Contracts%20Optimization.pdf\",\n            \"https://cspecc.utsa.edu/publications/files/Refereed_Papers/2020_Choo_BCPPA-blockchain-cond-priv-auth-prot.pdf\",\n            \"https://www.ekonomika.org.rs/sr/PDF/ekonomika/2019/clanci19-3/7.pdf\",\n            \"https://assets.cureusjournals.com/artifacts/upload/review_article/pdf/1099/20250319-214523-194a3z.pdf\"\n        ],\n        model_path=\"/kaggle/working/section_classifier.joblib\",\n        lang='en'\n    )\n    \n    # Evaluation (with mock true labels for demonstration)\n    y_true, y_pred = [], []\n    class_mapping = {\n        'ABSTRACT': 'abstract',\n        'INTRO': 'introduction',\n        '摘要': 'abstract',\n        '引言': 'introduction'\n    }\n    \n    # Generate mock evaluation data\n    for paper in papers:\n        # In real implementation, use actual ground truth labels\n        mock_true_labels = ['abstract', 'introduction', 'methods', 'results']\n        predicted_labels = list(paper['sections'].keys())[:4]  # First 4 sections\n        \n        for true, pred in zip(mock_true_labels, predicted_labels):\n            y_true.append(true)\n            y_pred.append(pred)\n\n    # Calculate metrics\n    base_metrics = detector.calculate_accuracy(y_true, y_pred)\n    extended_metrics = calculate_extended_metrics(y_true, y_pred)\n    \n    print(\"Base Metrics:\")\n    print(f\"Weighted Precision: {base_metrics['precision']:.2f}\")\n    print(f\"Weighted Recall: {base_metrics['recall']:.2f}\")\n    print(f\"Weighted F1: {base_metrics['f1']:.2f}\")\n    \n    print(\"\\nExtended Metrics:\")\n    print(f\"Macro Precision: {extended_metrics['precision_macro']:.2f}\")\n    print(f\"Macro Recall: {extended_metrics['recall_macro']:.2f}\")\n    print(f\"Macro F1: {extended_metrics['f1_macro']:.2f}\")\n    \n    print(\"\\nClass Distribution:\")\n    for cls, counts in extended_metrics['class_distribution'].items():\n        print(f\"{cls}: True={counts['true']}, Predicted={counts['predicted']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T18:34:49.311674Z","iopub.execute_input":"2025-05-27T18:34:49.311973Z","iopub.status.idle":"2025-05-27T18:34:50.133059Z","shell.execute_reply.started":"2025-05-27T18:34:49.311942Z","shell.execute_reply":"2025-05-27T18:34:50.131687Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1473/4032889041.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Train and save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSectionDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/section_classifier.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_1473/4032889041.py\u001b[0m in \u001b[0;36mload_training_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Implement actual data loading logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Train and save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"],"ename":"NameError","evalue":"name 'X_train' is not defined","output_type":"error"}],"execution_count":8}]}