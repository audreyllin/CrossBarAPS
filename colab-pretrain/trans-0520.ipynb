{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11876335,"sourceType":"datasetVersion","datasetId":7463918}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Install required packages (simplified)\n!pip install torch transformers sentence-transformers tqdm scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T21:26:16.748645Z","iopub.execute_input":"2025-05-20T21:26:16.749657Z","iopub.status.idle":"2025-05-20T21:26:21.134508Z","shell.execute_reply.started":"2025-05-20T21:26:16.749620Z","shell.execute_reply":"2025-05-20T21:26:21.133321Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import shutil\n\nshutil.copytree('/kaggle/input/db-19-txt', '/kaggle/working/db-19-txt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T21:26:21.136658Z","iopub.execute_input":"2025-05-20T21:26:21.137125Z","iopub.status.idle":"2025-05-20T21:26:21.166659Z","shell.execute_reply.started":"2025-05-20T21:26:21.137089Z","shell.execute_reply":"2025-05-20T21:26:21.165311Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/db-19-txt'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Cell 2: Configure environment and logging\nimport os\nimport logging\n\n# Suppress unnecessary warnings\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Reduce TensorFlow logging\nlogging.getLogger(\"transformers\").setLevel(logging.ERROR)\n\n# Configure main logger\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[logging.StreamHandler()]\n)\nlogger = logging.getLogger(__name__)\nlogger.info(\"Logging configured successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T21:26:21.168200Z","iopub.execute_input":"2025-05-20T21:26:21.169368Z","iopub.status.idle":"2025-05-20T21:26:21.176548Z","shell.execute_reply.started":"2025-05-20T21:26:21.169334Z","shell.execute_reply":"2025-05-20T21:26:21.175025Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Cell 3: Import packages with verification\nimport numpy as np\nimport sqlite3\nimport hashlib\nimport torch\nfrom typing import List, Dict\nfrom transformers import AutoModel, AutoTokenizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nlogger.info(\"Core packages imported successfully\")\n\n# Verify CUDA availability\nif torch.cuda.is_available():\n    logger.info(f\"CUDA enabled using {torch.cuda.get_device_name(0)}\")\nelse:\n    logger.warning(\"CUDA not available, using CPU\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T21:26:21.178542Z","iopub.execute_input":"2025-05-20T21:26:21.178898Z","iopub.status.idle":"2025-05-20T21:26:27.479138Z","shell.execute_reply.started":"2025-05-20T21:26:21.178872Z","shell.execute_reply":"2025-05-20T21:26:27.478021Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Cell 4: QnA System Class (enhanced)\nclass QnASystem:\n    def __init__(self, db_path: str = \"/kaggle/working/qna_db.sqlite\"):\n        self.db_path = db_path\n        self.conn = None\n        self.model = None\n        self.tokenizer = None\n        self._initialize_components()\n        self._verify_system_health()\n\n    def _initialize_components(self):\n        \"\"\"Initialize database and ML components with verification\"\"\"\n        try:\n            # Database setup with check_same_thread=False for notebook environments\n            self.conn = sqlite3.connect(self.db_path, check_same_thread=False)\n            self._initialize_db()\n            logger.info(\"Database component initialized\")\n            \n            # Model setup\n            self.tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n            self.model = AutoModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n            if torch.cuda.is_available():\n                self.model = self.model.to('cuda')\n            logger.info(\"Model loaded successfully\")\n            \n            # Test embedding generation\n            test_embed = self._text_to_vector(\"test\")\n            logger.debug(f\"Test embedding shape: {test_embed.shape}\")\n            \n        except Exception as e:\n            logger.error(f\"Initialization failed: {str(e)}\")\n            raise\n\n    def _verify_system_health(self):\n        \"\"\"Perform system health checks\"\"\"\n        cursor = self.conn.execute(\"SELECT count(*) FROM sqlite_master\")\n        if cursor.fetchone()[0] < 1:\n            raise RuntimeError(\"Database tables not initialized properly\")\n            \n        test_text = \"system health check\"\n        emb = self._text_to_vector(test_text)\n        if emb.shape != (768,):\n            raise RuntimeError(f\"Invalid embedding shape: {emb.shape}\")\n            \n        logger.info(\"System health verification passed\")\n\n    def _initialize_db(self):\n        \"\"\"Create database schema with error recovery\"\"\"\n        try:\n            self.conn.executescript(\"\"\"\n                CREATE TABLE IF NOT EXISTS qna_pairs (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    question TEXT UNIQUE NOT NULL,\n                    answer TEXT NOT NULL,\n                    category TEXT,\n                    keywords TEXT,\n                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n                );\n                CREATE TABLE IF NOT EXISTS qna_embeddings (\n                    qna_id INTEGER PRIMARY KEY,\n                    question_vector BLOB NOT NULL,\n                    FOREIGN KEY(qna_id) REFERENCES qna_pairs(id)\n                );\n            \"\"\")\n        except sqlite3.Error as e:\n            logger.error(f\"Database error: {str(e)}\")\n            raise\n\n    def _text_to_vector(self, text: str) -> np.ndarray:\n        \"\"\"Convert text to embedding vector with proper pooling\"\"\"\n        try:\n            inputs = self.tokenizer(\n                text, \n                return_tensors=\"pt\", \n                padding=True, \n                truncation=True, \n                max_length=512\n            )\n            \n            if torch.cuda.is_available():\n                inputs = {k: v.to('cuda') for k, v in inputs.items()}\n            \n            with torch.no_grad():\n                outputs = self.model(**inputs)\n            \n            # Mean pooling implementation\n            token_embeddings = outputs.last_hidden_state\n            attention_mask = inputs['attention_mask']\n            input_mask_expanded = (\n                attention_mask\n                .unsqueeze(-1)\n                .expand(token_embeddings.size())\n                .float()\n            )\n            embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n            embeddings = embeddings / sum_mask\n            \n            return embeddings.cpu().numpy().squeeze()\n        \n        except Exception as e:\n            logger.error(f\"Vectorization failed: {str(e)}\")\n            raise\n\n    def _get_embeddings(self) -> Dict[int, np.ndarray]:\n            \"\"\"Retrieve all stored embeddings from database\"\"\"\n            try:\n                cursor = self.conn.execute(\"\"\"\n                    SELECT qna_id, question_vector \n                    FROM qna_embeddings\n                \"\"\")\n                \n                embeddings = {}\n                for qna_id, vec_blob in cursor.fetchall():\n                    embeddings[qna_id] = np.frombuffer(vec_blob, dtype=np.float32)\n                \n                logger.debug(f\"Loaded {len(embeddings)} embeddings from database\")\n                return embeddings\n                \n            except sqlite3.Error as e:\n                logger.error(f\"Failed to load embeddings: {str(e)}\")\n                raise\n\n    def semantic_search(self, query: str, top_k: int = 5) -> List[Dict]:\n        \"\"\"Perform semantic search with similarity scoring\"\"\"\n        try:\n            # Generate query embedding\n            query_vector = self._text_to_vector(query)\n            \n            # Get stored embeddings\n            stored_embeddings = self._get_embeddings()\n            if not stored_embeddings:\n                logger.warning(\"No embeddings found in database\")\n                return []\n            \n            # Prepare data for similarity calculation\n            qna_ids = list(stored_embeddings.keys())\n            stored_vectors = np.array(list(stored_embeddings.values()))\n            \n            # Calculate cosine similarities\n            similarities = cosine_similarity(\n                [query_vector], \n                stored_vectors\n            ).squeeze()\n            \n            # Get top K results\n            top_indices = similarities.argsort()[-top_k:][::-1]\n            \n            # Retrieve full QnA information\n            results = []\n            for idx in top_indices:\n                qna_id = qna_ids[idx]\n                cursor = self.conn.execute(\"\"\"\n                    SELECT question, answer, category \n                    FROM qna_pairs \n                    WHERE id = ?\n                \"\"\", (qna_id,))\n                question, answer, category = cursor.fetchone()\n                \n                results.append({\n                    \"qna_id\": qna_id,\n                    \"question\": question,\n                    \"answer\": answer,\n                    \"category\": category,\n                    \"similarity\": float(similarities[idx])\n                })\n            \n            logger.info(f\"Found {len(results)} relevant results\")\n            return results\n            \n        except Exception as e:\n            logger.error(f\"Search failed: {str(e)}\")\n            raise\n\n    def close(self):\n        \"\"\"Close database connection\"\"\"\n        if self.conn:\n            self.conn.close()\n            self.conn = None\n            logger.info(\"Database connection closed\")\n            \n    def __del__(self):\n        \"\"\"Cleanup resources\"\"\"\n        self.close()\n        logger.info(\"System shutdown complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T21:26:27.480248Z","iopub.execute_input":"2025-05-20T21:26:27.480893Z","iopub.status.idle":"2025-05-20T21:26:27.503462Z","shell.execute_reply.started":"2025-05-20T21:26:27.480853Z","shell.execute_reply":"2025-05-20T21:26:27.502165Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Cell 5: Data ingestion with verification (fixed)\nqna_data = [\n    {\n        \"question\": \"What is blockchain?\",\n        \"answer\": \"A decentralized digital ledger technology...\",\n        \"category\": \"Blockchain Basics\",\n        \"keywords\": \"distributed ledger, cryptography\"\n    }\n]\n\n# Close any existing connection\nif 'system' in locals():\n    system.conn.close()\n    del system\n\nsystem = QnASystem()\n\ntry:\n    logger.info(\"Starting data ingestion...\")\n    \n    # Explicit transaction management\n    with system.conn:\n        system.conn.executemany(\"\"\"\n            INSERT OR IGNORE INTO qna_pairs \n            (question, answer, category, keywords)\n            VALUES (?, ?, ?, ?)\n        \"\"\", [(q[\"question\"], q[\"answer\"], q[\"category\"], q[\"keywords\"]) for q in qna_data])\n\n    # Enable WAL mode for better concurrency\n    system.conn.execute(\"PRAGMA journal_mode=WAL;\")\n    \n    # Verify insertion\n    with system.conn:\n        cursor = system.conn.execute(\"SELECT COUNT(*) FROM qna_pairs\")\n        count = cursor.fetchone()[0]\n    \n    logger.info(f\"Successfully stored {count} QnA pairs\")\n    \n    if count < 1:\n        raise RuntimeError(\"Data insertion failed\")\n\nexcept Exception as e:\n    logger.error(f\"Data ingestion failed: {str(e)}\")\n    raise\nfinally:\n    system.conn.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T21:26:27.504873Z","iopub.execute_input":"2025-05-20T21:26:27.505374Z","iopub.status.idle":"2025-05-20T21:26:34.497143Z","shell.execute_reply.started":"2025-05-20T21:26:27.505278Z","shell.execute_reply":"2025-05-20T21:26:34.496048Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747776389.935066    8568 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747776389.943689    8568 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Cell 6: Enhanced search test (fixed)\ntry:\n    logger.info(\"\\n=== Testing Search Functionality ===\")\n    test_query = \"distributed ledger technology\"\n    \n    # Create new connection for search\n   # In your search test cell:\n    with sqlite3.connect(\"/kaggle/working/qna_db.sqlite\", check_same_thread=False) as temp_conn:\n        system.conn = temp_conn\n        results = system.semantic_search(test_query)\n    \n    if not results:\n        logger.warning(\"No results found for test query\")\n    else:\n        logger.info(\"Top 3 results:\")\n        for i, result in enumerate(results[:3], 1):\n            logger.info(f\"{i}. {result['answer']}\")\n            \nexcept Exception as e:\n    logger.error(f\"Search test failed: {str(e)}\")\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T21:26:34.498420Z","iopub.execute_input":"2025-05-20T21:26:34.499191Z","iopub.status.idle":"2025-05-20T21:26:34.565964Z","shell.execute_reply.started":"2025-05-20T21:26:34.499164Z","shell.execute_reply":"2025-05-20T21:26:34.564842Z"}},"outputs":[],"execution_count":9}]}